{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Income  Sex   Age  Race  Edu  Diastolic    Systolic      Pulse   BMI   HDL  \\\n",
      "0    4.56  1.0  70.0   3.0  3.2  69.000000  124.333333  61.333333  25.6  46.0   \n",
      "1    5.00  2.0  49.0   3.0  5.0  64.000000  102.666667  66.000000  22.4  63.0   \n",
      "2    1.59  1.0  54.0   4.0  3.2  96.000000  160.000000  71.533333  25.4  60.0   \n",
      "3    2.37  1.0  73.0   3.0  2.8  58.000000  134.666667  62.666667  34.0  41.0   \n",
      "4    5.00  1.0  42.0   3.0  3.4  82.333333  116.000000  63.666667  30.4  49.0   \n",
      "\n",
      "    Trig    LDL  TCHOL  kidneys_eGFR  Diabetes  CurrentSmoker  isActive  \\\n",
      "0  186.0  207.0  289.0     77.244722       2.0            2.0       2.0   \n",
      "1   60.0  108.0  183.0    101.217970       2.0            2.0       2.0   \n",
      "2  102.0  179.0  261.0     71.863349       2.0            2.0       2.0   \n",
      "3  105.0  110.0  172.0     72.459827       2.0            2.0       1.0   \n",
      "4   98.0  203.0  275.0     79.009375       2.0            2.0       2.0   \n",
      "\n",
      "   isInsured  \n",
      "0        1.0  \n",
      "1        1.0  \n",
      "2        1.0  \n",
      "3        1.0  \n",
      "4        2.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('NHANES_data_train.csv')  # Adjust the path to your dataset\n",
    "\n",
    "# Assuming 'ParticipantID' is a column in your DataFrame, set it as the index\n",
    "df.set_index('ParticipantID', inplace=True)\n",
    "\n",
    "# Separate features and target if they're all in the same DataFrame\n",
    "X = df.drop('MI', axis=1)  # Exclude 'MI' which is the target variable\n",
    "y = df['MI']\n",
    "\n",
    "# Instantiate the KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)  # Adjust 'n_neighbors' as needed\n",
    "\n",
    "# Apply imputation to the DataFrame\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Print the imputed DataFrame to verify\n",
    "print(X_imputed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the kNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # Adjust n_neighbors as needed\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_proba_knn = knn.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Create a DataFrame with ParticipantID and predicted probabilities for kNN\n",
    "output_df_knn = pd.DataFrame({'ParticipantID': X_test.index, 'Pred_Probability': y_pred_proba_knn})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df_knn.to_csv('kNN_pred.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000)  # Adjust max_iter as needed\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict probabilities for the test set using logistic regression\n",
    "y_pred_proba_logreg = logreg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Create a DataFrame with ParticipantID and predicted probabilities for logistic regression\n",
    "output_df_logreg = pd.DataFrame({'ParticipantID': X_test.index, 'Pred_Probability': y_pred_proba_logreg})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df_logreg.to_csv('regression_pred.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'knn__n_neighbors': 6, 'knn__weights': 'distance'}\n",
      "Best cross-validation score: 0.9641437818844597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X_train_scaled and X_test_scaled are already defined\n",
    "\n",
    "# Define a pipeline combining a scaler and the kNN classifier\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Define a parameter grid to search over\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': range(1, 31),\n",
    "    'knn__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Setup grid search\n",
    "grid_search_knn = GridSearchCV(knn_pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters:\", grid_search_knn.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search_knn.best_score_)\n",
    "\n",
    "# Predict with the best estimator\n",
    "y_pred_proba_knn = grid_search_knn.predict_proba(X_test)[:, 1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
